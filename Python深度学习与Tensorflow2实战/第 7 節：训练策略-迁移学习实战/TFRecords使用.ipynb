{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFRecords制作\n",
    "\n",
    "为了高效地读取数据，可以将数据进行序列化存储，这样也便于网络流式读取数据。TFRecord是一种比较常用的存储二进制序列数据的方法\n",
    "\n",
    "- tf.Example类是一种将数据表示为{\"string\": value}形式的meassage类型，Tensorflow经常使用tf.Example来写入、读取TFRecord数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T08:33:54.695421Z",
     "start_time": "2019-10-02T08:33:53.467501Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 通常情况下，tf.Example中可以使用以下几种格式：\n",
    "\n",
    "- tf.train.BytesList: 可以使用的类型包括 string和byte\n",
    "- tf.train.FloatList: 可以使用的类型包括 float和double\n",
    "- tf.train.Int64List: 可以使用的类型包括 enum,bool, int32, uint32, int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "转化实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T08:33:54.702109Z",
     "start_time": "2019-10-02T08:33:54.697082Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string/byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Return a float_list form a float/double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Return a int64_list from a bool/enum/int/uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-02T08:33:54.936511Z",
     "start_time": "2019-10-02T08:33:54.704811Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bytes_list {\n",
      "  value: \"test_string\"\n",
      "}\n",
      "\n",
      "bytes_list {\n",
      "  value: \"test_string\"\n",
      "}\n",
      "\n",
      "float_list {\n",
      "  value: 2.7182817459106445\n",
      "}\n",
      "\n",
      "int64_list {\n",
      "  value: 1\n",
      "}\n",
      "\n",
      "int64_list {\n",
      "  value: 1\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tf.train.BytesList\n",
    "print(_bytes_feature(b'test_string'))\n",
    "print(_bytes_feature('test_string'.encode('utf8')))\n",
    "\n",
    "# tf.train.FloatList\n",
    "print(_float_feature(np.exp(1)))\n",
    "\n",
    "# tf.train.Int64List\n",
    "print(_int64_feature(True))\n",
    "print(_int64_feature(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tfrecord制作方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建tf.Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def serialize_example(feature0, feature1, feature2, feature3):\n",
    "    \"\"\"\n",
    "    创建tf.Example\n",
    "    \"\"\"\n",
    "    \n",
    "    # 转换成相应类型\n",
    "    feature = {\n",
    "        'feature0': _int64_feature(feature0),\n",
    "        'feature1': _int64_feature(feature1),\n",
    "        'feature2': _bytes_feature(feature2),\n",
    "        'feature3': _float_feature(feature3),\n",
    "    }\n",
    "    #使用tf.train.Example来创建\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    #SerializeToString方法转换为二进制字符串\n",
    "    return example_proto.SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 数据量\n",
    "n_observations = int(1e4)\n",
    "\n",
    "# Boolean feature\n",
    "feature0 = np.random.choice([False, True], n_observations)\n",
    "\n",
    "# Integer feature\n",
    "feature1 = np.random.randint(0, 5, n_observations)\n",
    "\n",
    "# String feature\n",
    "strings = np.array([b'cat', b'dog', b'chicken', b'horse', b'goat'])\n",
    "feature2 = strings[feature1]\n",
    "\n",
    "# Float feature\n",
    "feature3 = np.random.randn(n_observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = 'tfrecord-1'\n",
    "\n",
    "with tf.io.TFRecordWriter(filename) as writer:\n",
    "    for i in range(n_observations):\n",
    "        example = serialize_example(feature0[i], feature1[i], feature2[i], feature3[i])\n",
    "        writer.write(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载tfrecord文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TFRecordDatasetV2 shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = [filename]\n",
    "\n",
    "# 读取\n",
    "raw_dataset = tf.data.TFRecordDataset(filenames)\n",
    "raw_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 图像数据处理实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# image_path = '../img/'\n",
    "# images = glob.glob(image_path + '*.jpg')\n",
    "\n",
    "# for fname in images:\n",
    "#     image = mpimg.imread(fname)\n",
    "#     f, (ax1) = plt.subplots(1, 1, figsize=(8,8))\n",
    "#     f.subplots_adjust(hspace = .2, wspace = .05)\n",
    "    \n",
    "#     ax1.imshow(image)\n",
    "#     ax1.set_title('Image', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_labels = {\n",
    "    'dog': 0,\n",
    "    'kangaroo': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 制作TFRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 读数据，binary格式\n",
    "image_string = open('./img/dog.jpg', 'rb').read()\n",
    "label = image_labels['dog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string/byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Return a float_list form a float/double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Return a int64_list from a bool/enum/int/uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "# 创建图像数据的Example\n",
    "def image_example(image_string, label):\n",
    "    image_shape = tf.image.decode_jpeg(image_string).shape\n",
    "\n",
    "    feature = {\n",
    "        'height': _int64_feature(image_shape[0]),\n",
    "        'width': _int64_feature(image_shape[1]),\n",
    "        'depth': _int64_feature(image_shape[2]),\n",
    "        'label': _int64_feature(label),\n",
    "        'image_raw': _bytes_feature(image_string),\n",
    "    }\n",
    "\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features {\n",
      "  feature {\n",
      "    key: \"depth\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 3\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"height\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 576\n",
      "      }\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "#打印部分信息\n",
    "image_example_proto = image_example(image_string, label)\n",
    "\n",
    "for line in str(image_example_proto).split('\\n')[:15]:\n",
    "    print(line)\n",
    "print('...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1 of 2 images.\n",
      "Processed 2 of 2 images.\n",
      " Wrote 2 images to images.tfrecord\n"
     ]
    }
   ],
   "source": [
    "# 制作 `images.tfrecords`.\n",
    "\n",
    "image_path = './img/'\n",
    "images = glob.glob(image_path + '*.jpg')\n",
    "record_file = 'images.tfrecord'\n",
    "counter = 0\n",
    "\n",
    "with tf.io.TFRecordWriter(record_file) as writer:\n",
    "    for fname in images:\n",
    "        with open(fname, 'rb') as f:\n",
    "            image_string = f.read()\n",
    "            label = image_labels[os.path.basename(fname).replace('.jpg', '')]\n",
    "            \n",
    "            # `tf.Example` \n",
    "            tf_example = image_example(image_string, label)\n",
    "            \n",
    "            # 将`tf.example` 写入 TFRecord \n",
    "            writer.write(tf_example.SerializeToString())\n",
    "            \n",
    "            counter += 1\n",
    "            print('Processed {:d} of {:d} images.'.format(\n",
    "                counter, len(images)))\n",
    "\n",
    "print(' Wrote {} images to {}'.format(counter, record_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载制作好的TFRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TFRecordDatasetV2 shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_dataset = tf.data.TFRecordDataset('./images.tfrecord')\n",
    "raw_train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example数据都进行了序列化，还需要解析以下之前写入的序列化string\n",
    "- tf.io.parse_single_example(example_proto, feature_description)函数可以解析单条example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 解析的格式需要跟之前创建example时一致\n",
    "image_feature_description = {\n",
    "    'height'   : tf.io.FixedLenFeature([], tf.int64),\n",
    "    'width'    : tf.io.FixedLenFeature([], tf.int64),\n",
    "    'depth'    : tf.io.FixedLenFeature([], tf.int64),\n",
    "    'label'    : tf.io.FixedLenFeature([], tf.int64),\n",
    "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在看起来仅仅完成了一个样本的解析，实际数据不可能一个个来写吧，可以定义一个映射规则map函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: ((416, 416, 3), ()), types: (tf.float32, tf.int64)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_tf_example(example_proto):\n",
    "    # 解析出来\n",
    "    parsed_example = tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "    \n",
    "    # 预处理\n",
    "    x_train = tf.image.decode_jpeg(parsed_example['image_raw'], channels=3)\n",
    "    x_train = tf.image.resize(x_train, (416, 416))\n",
    "    x_train /= 255.\n",
    "\n",
    "    lebel = parsed_example['label']\n",
    "    y_train = lebel\n",
    "    \n",
    "    return x_train, y_train\n",
    "\n",
    "train_dataset = raw_train_dataset.map(parse_tf_example)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 制作训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RepeatDataset shapes: ((None, 416, 416, 3), (None,)), types: (tf.float32, tf.int64)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "train_ds = train_dataset.shuffle(buffer_size=10000).batch(2).repeat(num_epochs)\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (2, 416, 416, 3) tf.Tensor([0 1], shape=(2,), dtype=int64)\n",
      "1 (2, 416, 416, 3) tf.Tensor([0 1], shape=(2,), dtype=int64)\n",
      "2 (2, 416, 416, 3) tf.Tensor([1 0], shape=(2,), dtype=int64)\n",
      "3 (2, 416, 416, 3) tf.Tensor([0 1], shape=(2,), dtype=int64)\n",
      "4 (2, 416, 416, 3) tf.Tensor([1 0], shape=(2,), dtype=int64)\n",
      "5 (2, 416, 416, 3) tf.Tensor([0 1], shape=(2,), dtype=int64)\n",
      "6 (2, 416, 416, 3) tf.Tensor([0 1], shape=(2,), dtype=int64)\n",
      "7 (2, 416, 416, 3) tf.Tensor([0 1], shape=(2,), dtype=int64)\n",
      "8 (2, 416, 416, 3) tf.Tensor([1 0], shape=(2,), dtype=int64)\n",
      "9 (2, 416, 416, 3) tf.Tensor([1 0], shape=(2,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for batch, (x, y) in enumerate(train_ds):\n",
    "    print(batch, x.shape, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 1s 54ms/step - loss: 43.7451 - accuracy: 0.6237\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 36ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 41ms/step - loss: 0.0229 - accuracy: 0.9802\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 30ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 29ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 33ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 27ms/step - loss: 0.0000e+00 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9a8325ba90>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python38",
   "language": "python",
   "name": "python38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
